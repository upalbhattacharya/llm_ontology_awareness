#!/bin/bash

#SBATCH --job-name=ontollm_1
#SBATCH --nodes=1
#SBATCH --partition=gpua16
#SBATCH --gres=gpu:1
#SBATCH --time=05:00:00
#SBATCH --output=/scratch/bhatt006/run_logs/%x_%j.out
#SBATCH --error=/scratch/bhatt006/run_logs/%x_%j.err

# Load Modules

module load cuda/12.5

# Define Visible GPUs
CUDA_VISIBLE_DEVICES=0,1,2,3

# Execution

# Activate Virtual Environment
source /scratch/bhatt006/.venvs/llm_ontology_awareness/bin/activate

# Change directory
cd /scratch/bhatt006/Repos/llm_ontology_awareness/src/llm_ontology_awareness/model/hugging_face || exit

# Execute

python3 predict.py \
  -f /scratch/bhatt006/Repos/llm_ontology_awareness/run_args/term_typing/ranked_retrieval/zero_shot/astronomy-ontology/llama3-7B/c1e9866b-0596-4221-9336-58f2e8b6c80c.json
